{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumbokh/csu1112-class/blob/main/class/vision/IMAGEAI_ObjectDetectionTrain_HoloLens.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXFProzuNCFz"
      },
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klYO3yuivSRI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd32041d-c653-4e1f-aba8-af25e416b5a4"
      },
      "source": [
        "!pip3 install albumentations --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting albumentations\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/58/63fb1d742dc42d9ba2800ea741de1f2bc6bb05548d8724aa84794042eaf2/albumentations-0.5.2-py3-none-any.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 3.7MB/s \n",
            "\u001b[?25hCollecting imgaug>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/b1/af3142c4a85cba6da9f4ebb5ff4e21e2616309552caca5e8acefe9840622/imgaug-0.4.0-py2.py3-none-any.whl (948kB)\n",
            "\u001b[K     |████████████████████████████████| 952kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.4.1)\n",
            "Collecting opencv-python-headless>=4.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/fc/4da675cc522a749ebbcf85c5a63fba844b2d44c87e6f24e3fdb147df3270/opencv_python_headless-4.5.1.48-cp36-cp36m-manylinux2014_x86_64.whl (37.6MB)\n",
            "\u001b[K     |████████████████████████████████| 37.6MB 74kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-image>=0.16.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (0.16.2)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (4.1.2.30)\n",
            "Requirement already satisfied, skipping upgrade: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (1.7.1)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (2.5)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n",
            "Installing collected packages: imgaug, opencv-python-headless, albumentations\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.5.2 imgaug-0.4.0 opencv-python-headless-4.5.1.48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65xxaL7NIzMi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d2dc2a10-0c07-4601-fcc8-07372ce2f608"
      },
      "source": [
        "!pip install -U tensorflow keras opencv-python\n",
        "!pip3 install imageai --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.4.0)\n",
            "Requirement already up-to-date: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Collecting opencv-python\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/20/4d78eb1ce337efd609ade8ebe0c82260cd47dd73f8c57dcfe4814c6a3b59/opencv_python-4.5.1.48-cp36-cp36m-manylinux2014_x86_64.whl (50.4MB)\n",
            "\u001b[K     |████████████████████████████████| 50.4MB 67kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied, skipping upgrade: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (51.1.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.3)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.0)\n",
            "Installing collected packages: opencv-python\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "Successfully installed opencv-python-4.5.1.48\n",
            "Collecting imageai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/44/3d5d8ef572888025666eec284e85f9243faf06ca8c12085dcff1ca9754ed/imageai-2.1.6-py3-none-any.whl (160kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 4.0MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/d6/8c4dfb23151d5a494c66ebbfdb5c8c433b44ec07fae52da5939fcda0943f/matplotlib-3.3.2-cp36-cp36m-manylinux1_x86_64.whl (11.6MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6MB 17.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.6/dist-packages (from imageai) (4.5.1.48)\n",
            "Requirement already satisfied, skipping upgrade: pillow==7.0.0 in /usr/local/lib/python3.6/dist-packages (from imageai) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py==2.10.0 in /usr/local/lib/python3.6/dist-packages (from imageai) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: keras==2.4.3 in /usr/local/lib/python3.6/dist-packages (from imageai) (2.4.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from imageai) (1.4.1)\n",
            "Collecting keras-resnet==0.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/76/d4/a35cbd07381139dda4db42c81b88c59254faac026109022727b45b31bcad/keras-resnet-0.2.0.tar.gz\n",
            "Collecting numpy==1.19.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/f7/a7d7e0de99a7b43bd95aaddcf29e65b5a185ca389dd1329a53cc986edc38/numpy-1.19.3-cp36-cp36m-manylinux2010_x86_64.whl (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 219kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.2->imageai) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.2->imageai) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.2->imageai) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.2->imageai) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2020.06.20 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.2->imageai) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from h5py==2.10.0->imageai) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.4.3->imageai) (3.13)\n",
            "Building wheels for collected packages: keras-resnet\n",
            "  Building wheel for keras-resnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-resnet: filename=keras_resnet-0.2.0-py2.py3-none-any.whl size=20486 sha256=f76a706b21e34f6684045d2eefe4e04ac15a3f7693305218084d62df7b029873\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/09/a5/497a30fd9ad9964e98a1254d1e164bcd1b8a5eda36197ecb3c\n",
            "Successfully built keras-resnet\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, matplotlib, keras-resnet, imageai\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "Successfully installed imageai-2.1.6 keras-resnet-0.2.0 matplotlib-3.3.2 numpy-1.19.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g8UU8xGNPc_"
      },
      "source": [
        "## 2. Download Dataset and unzip the file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5CfbswTJPLs"
      },
      "source": [
        "# !wget https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/hololens.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l4mfIo4AzaU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "fbed1fe1-9dbc-482b-e01b-9209ff0fe069"
      },
      "source": [
        "!wget https://github.com/picashuo/ImageData/releases/download/essential-v5/hololens.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-01 01:39:28--  https://github.com/picashuo/ImageData/releases/download/essential-v5/hololens.zip\n",
            "Resolving github.com (github.com)... 52.192.72.89\n",
            "Connecting to github.com (github.com)|52.192.72.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/203287045/4d214a80-c525-11e9-8b63-39e24e55d4fb?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190901%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190901T013928Z&X-Amz-Expires=300&X-Amz-Signature=a34b17dcbd7dadf4d50c94ade339683411066a448540f53bd98981eb43bc3a88&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dhololens.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2019-09-01 01:39:28--  https://github-production-release-asset-2e65be.s3.amazonaws.com/203287045/4d214a80-c525-11e9-8b63-39e24e55d4fb?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190901%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190901T013928Z&X-Amz-Expires=300&X-Amz-Signature=a34b17dcbd7dadf4d50c94ade339683411066a448540f53bd98981eb43bc3a88&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dhololens.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.131.131\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.131.131|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9051805 (8.6M) [application/octet-stream]\n",
            "Saving to: ‘hololens.zip.1’\n",
            "\n",
            "hololens.zip.1      100%[===================>]   8.63M  1.10MB/s    in 8.7s    \n",
            "\n",
            "2019-09-01 01:39:37 (1018 KB/s) - ‘hololens.zip.1’ saved [9051805/9051805]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOPM87BzJi0s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4292c7d-ed76-422d-8055-c78786af830d"
      },
      "source": [
        "!unzip hololens.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  hololens.zip\n",
            "   creating: hololens/\n",
            "  inflating: hololens/hololens_test.pkl  \n",
            "  inflating: hololens/hololens_train.pkl  \n",
            "   creating: hololens/train/\n",
            "   creating: hololens/train/annotations/\n",
            "  inflating: hololens/train/annotations/image (1).xml  \n",
            "  inflating: hololens/train/annotations/image (10).xml  \n",
            "  inflating: hololens/train/annotations/image (100).xml  \n",
            "  inflating: hololens/train/annotations/image (101).xml  \n",
            "  inflating: hololens/train/annotations/image (102).xml  \n",
            "  inflating: hololens/train/annotations/image (103).xml  \n",
            "  inflating: hololens/train/annotations/image (104).xml  \n",
            "  inflating: hololens/train/annotations/image (105).xml  \n",
            "  inflating: hololens/train/annotations/image (106).xml  \n",
            "  inflating: hololens/train/annotations/image (107).xml  \n",
            "  inflating: hololens/train/annotations/image (108).xml  \n",
            "  inflating: hololens/train/annotations/image (109).xml  \n",
            "  inflating: hololens/train/annotations/image (11).xml  \n",
            "  inflating: hololens/train/annotations/image (110).xml  \n",
            "  inflating: hololens/train/annotations/image (111).xml  \n",
            "  inflating: hololens/train/annotations/image (112).xml  \n",
            "  inflating: hololens/train/annotations/image (113).xml  \n",
            "  inflating: hololens/train/annotations/image (114).xml  \n",
            "  inflating: hololens/train/annotations/image (115).xml  \n",
            "  inflating: hololens/train/annotations/image (116).xml  \n",
            "  inflating: hololens/train/annotations/image (117).xml  \n",
            "  inflating: hololens/train/annotations/image (118).xml  \n",
            "  inflating: hololens/train/annotations/image (119).xml  \n",
            "  inflating: hololens/train/annotations/image (12).xml  \n",
            "  inflating: hololens/train/annotations/image (120).xml  \n",
            "  inflating: hololens/train/annotations/image (121).xml  \n",
            "  inflating: hololens/train/annotations/image (122).xml  \n",
            "  inflating: hololens/train/annotations/image (123).xml  \n",
            "  inflating: hololens/train/annotations/image (124).xml  \n",
            "  inflating: hololens/train/annotations/image (125).xml  \n",
            "  inflating: hololens/train/annotations/image (126).xml  \n",
            "  inflating: hololens/train/annotations/image (127).xml  \n",
            "  inflating: hololens/train/annotations/image (128).xml  \n",
            "  inflating: hololens/train/annotations/image (129).xml  \n",
            "  inflating: hololens/train/annotations/image (13).xml  \n",
            "  inflating: hololens/train/annotations/image (130).xml  \n",
            "  inflating: hololens/train/annotations/image (131).xml  \n",
            "  inflating: hololens/train/annotations/image (132).xml  \n",
            "  inflating: hololens/train/annotations/image (133).xml  \n",
            "  inflating: hololens/train/annotations/image (134).xml  \n",
            "  inflating: hololens/train/annotations/image (135).xml  \n",
            "  inflating: hololens/train/annotations/image (136).xml  \n",
            "  inflating: hololens/train/annotations/image (137).xml  \n",
            "  inflating: hololens/train/annotations/image (138).xml  \n",
            "  inflating: hololens/train/annotations/image (14).xml  \n",
            "  inflating: hololens/train/annotations/image (140).xml  \n",
            "  inflating: hololens/train/annotations/image (141).xml  \n",
            "  inflating: hololens/train/annotations/image (142).xml  \n",
            "  inflating: hololens/train/annotations/image (143).xml  \n",
            "  inflating: hololens/train/annotations/image (144).xml  \n",
            "  inflating: hololens/train/annotations/image (145).xml  \n",
            "  inflating: hololens/train/annotations/image (146).xml  \n",
            "  inflating: hololens/train/annotations/image (147).xml  \n",
            "  inflating: hololens/train/annotations/image (148).xml  \n",
            "  inflating: hololens/train/annotations/image (149).xml  \n",
            "  inflating: hololens/train/annotations/image (15).xml  \n",
            "  inflating: hololens/train/annotations/image (150).xml  \n",
            "  inflating: hololens/train/annotations/image (151).xml  \n",
            "  inflating: hololens/train/annotations/image (152).xml  \n",
            "  inflating: hololens/train/annotations/image (153).xml  \n",
            "  inflating: hololens/train/annotations/image (154).xml  \n",
            "  inflating: hololens/train/annotations/image (155).xml  \n",
            "  inflating: hololens/train/annotations/image (156).xml  \n",
            "  inflating: hololens/train/annotations/image (157).xml  \n",
            "  inflating: hololens/train/annotations/image (158).xml  \n",
            "  inflating: hololens/train/annotations/image (159).xml  \n",
            "  inflating: hololens/train/annotations/image (16).xml  \n",
            "  inflating: hololens/train/annotations/image (160).xml  \n",
            "  inflating: hololens/train/annotations/image (161).xml  \n",
            "  inflating: hololens/train/annotations/image (162).xml  \n",
            "  inflating: hololens/train/annotations/image (163).xml  \n",
            "  inflating: hololens/train/annotations/image (164).xml  \n",
            "  inflating: hololens/train/annotations/image (165).xml  \n",
            "  inflating: hololens/train/annotations/image (166).xml  \n",
            "  inflating: hololens/train/annotations/image (167).xml  \n",
            "  inflating: hololens/train/annotations/image (168).xml  \n",
            "  inflating: hololens/train/annotations/image (169).xml  \n",
            "  inflating: hololens/train/annotations/image (17).xml  \n",
            "  inflating: hololens/train/annotations/image (170).xml  \n",
            "  inflating: hololens/train/annotations/image (171).xml  \n",
            "  inflating: hololens/train/annotations/image (172).xml  \n",
            "  inflating: hololens/train/annotations/image (173).xml  \n",
            "  inflating: hololens/train/annotations/image (174).xml  \n",
            "  inflating: hololens/train/annotations/image (175).xml  \n",
            "  inflating: hololens/train/annotations/image (176).xml  \n",
            "  inflating: hololens/train/annotations/image (177).xml  \n",
            "  inflating: hololens/train/annotations/image (178).xml  \n",
            "  inflating: hololens/train/annotations/image (179).xml  \n",
            "  inflating: hololens/train/annotations/image (18).xml  \n",
            "  inflating: hololens/train/annotations/image (180).xml  \n",
            "  inflating: hololens/train/annotations/image (181).xml  \n",
            "  inflating: hololens/train/annotations/image (182).xml  \n",
            "  inflating: hololens/train/annotations/image (183).xml  \n",
            "  inflating: hololens/train/annotations/image (184).xml  \n",
            "  inflating: hololens/train/annotations/image (185).xml  \n",
            "  inflating: hololens/train/annotations/image (186).xml  \n",
            "  inflating: hololens/train/annotations/image (187).xml  \n",
            "  inflating: hololens/train/annotations/image (188).xml  \n",
            "  inflating: hololens/train/annotations/image (189).xml  \n",
            "  inflating: hololens/train/annotations/image (19).xml  \n",
            "  inflating: hololens/train/annotations/image (190).xml  \n",
            "  inflating: hololens/train/annotations/image (191).xml  \n",
            "  inflating: hololens/train/annotations/image (192).xml  \n",
            "  inflating: hololens/train/annotations/image (193).xml  \n",
            "  inflating: hololens/train/annotations/image (194).xml  \n",
            "  inflating: hololens/train/annotations/image (195).xml  \n",
            "  inflating: hololens/train/annotations/image (196).xml  \n",
            "  inflating: hololens/train/annotations/image (197).xml  \n",
            "  inflating: hololens/train/annotations/image (198).xml  \n",
            "  inflating: hololens/train/annotations/image (199).xml  \n",
            "  inflating: hololens/train/annotations/image (2).xml  \n",
            "  inflating: hololens/train/annotations/image (20).xml  \n",
            "  inflating: hololens/train/annotations/image (200).xml  \n",
            "  inflating: hololens/train/annotations/image (201).xml  \n",
            "  inflating: hololens/train/annotations/image (202).xml  \n",
            "  inflating: hololens/train/annotations/image (203).xml  \n",
            "  inflating: hololens/train/annotations/image (204).xml  \n",
            "  inflating: hololens/train/annotations/image (205).xml  \n",
            "  inflating: hololens/train/annotations/image (206).xml  \n",
            "  inflating: hololens/train/annotations/image (207).xml  \n",
            "  inflating: hololens/train/annotations/image (208).xml  \n",
            "  inflating: hololens/train/annotations/image (209).xml  \n",
            "  inflating: hololens/train/annotations/image (21).xml  \n",
            "  inflating: hololens/train/annotations/image (210).xml  \n",
            "  inflating: hololens/train/annotations/image (211).xml  \n",
            "  inflating: hololens/train/annotations/image (212).xml  \n",
            "  inflating: hololens/train/annotations/image (213).xml  \n",
            "  inflating: hololens/train/annotations/image (214).xml  \n",
            "  inflating: hololens/train/annotations/image (215).xml  \n",
            "  inflating: hololens/train/annotations/image (216).xml  \n",
            "  inflating: hololens/train/annotations/image (217).xml  \n",
            "  inflating: hololens/train/annotations/image (218).xml  \n",
            "  inflating: hololens/train/annotations/image (219).xml  \n",
            "  inflating: hololens/train/annotations/image (22).xml  \n",
            "  inflating: hololens/train/annotations/image (220).xml  \n",
            "  inflating: hololens/train/annotations/image (221).xml  \n",
            "  inflating: hololens/train/annotations/image (222).xml  \n",
            "  inflating: hololens/train/annotations/image (223).xml  \n",
            "  inflating: hololens/train/annotations/image (224).xml  \n",
            "  inflating: hololens/train/annotations/image (225).xml  \n",
            "  inflating: hololens/train/annotations/image (226).xml  \n",
            "  inflating: hololens/train/annotations/image (227).xml  \n",
            "  inflating: hololens/train/annotations/image (228).xml  \n",
            "  inflating: hololens/train/annotations/image (229).xml  \n",
            "  inflating: hololens/train/annotations/image (23).xml  \n",
            "  inflating: hololens/train/annotations/image (230).xml  \n",
            "  inflating: hololens/train/annotations/image (231).xml  \n",
            "  inflating: hololens/train/annotations/image (232).xml  \n",
            "  inflating: hololens/train/annotations/image (233).xml  \n",
            "  inflating: hololens/train/annotations/image (234).xml  \n",
            "  inflating: hololens/train/annotations/image (235).xml  \n",
            "  inflating: hololens/train/annotations/image (236).xml  \n",
            "  inflating: hololens/train/annotations/image (237).xml  \n",
            "  inflating: hololens/train/annotations/image (238).xml  \n",
            "  inflating: hololens/train/annotations/image (239).xml  \n",
            "  inflating: hololens/train/annotations/image (24).xml  \n",
            "  inflating: hololens/train/annotations/image (240).xml  \n",
            "  inflating: hololens/train/annotations/image (241).xml  \n",
            "  inflating: hololens/train/annotations/image (25).xml  \n",
            "  inflating: hololens/train/annotations/image (26).xml  \n",
            "  inflating: hololens/train/annotations/image (27).xml  \n",
            "  inflating: hololens/train/annotations/image (28).xml  \n",
            "  inflating: hololens/train/annotations/image (29).xml  \n",
            "  inflating: hololens/train/annotations/image (3).xml  \n",
            "  inflating: hololens/train/annotations/image (30).xml  \n",
            "  inflating: hololens/train/annotations/image (31).xml  \n",
            "  inflating: hololens/train/annotations/image (32).xml  \n",
            "  inflating: hololens/train/annotations/image (33).xml  \n",
            "  inflating: hololens/train/annotations/image (34).xml  \n",
            "  inflating: hololens/train/annotations/image (35).xml  \n",
            "  inflating: hololens/train/annotations/image (36).xml  \n",
            "  inflating: hololens/train/annotations/image (37).xml  \n",
            "  inflating: hololens/train/annotations/image (38).xml  \n",
            "  inflating: hololens/train/annotations/image (39).xml  \n",
            "  inflating: hololens/train/annotations/image (4).xml  \n",
            "  inflating: hololens/train/annotations/image (40).xml  \n",
            "  inflating: hololens/train/annotations/image (41).xml  \n",
            "  inflating: hololens/train/annotations/image (42).xml  \n",
            "  inflating: hololens/train/annotations/image (43).xml  \n",
            "  inflating: hololens/train/annotations/image (44).xml  \n",
            "  inflating: hololens/train/annotations/image (45).xml  \n",
            "  inflating: hololens/train/annotations/image (46).xml  \n",
            "  inflating: hololens/train/annotations/image (47).xml  \n",
            "  inflating: hololens/train/annotations/image (48).xml  \n",
            "  inflating: hololens/train/annotations/image (49).xml  \n",
            "  inflating: hololens/train/annotations/image (5).xml  \n",
            "  inflating: hololens/train/annotations/image (50).xml  \n",
            "  inflating: hololens/train/annotations/image (51).xml  \n",
            "  inflating: hololens/train/annotations/image (52).xml  \n",
            "  inflating: hololens/train/annotations/image (53).xml  \n",
            "  inflating: hololens/train/annotations/image (54).xml  \n",
            "  inflating: hololens/train/annotations/image (55).xml  \n",
            "  inflating: hololens/train/annotations/image (56).xml  \n",
            "  inflating: hololens/train/annotations/image (57).xml  \n",
            "  inflating: hololens/train/annotations/image (58).xml  \n",
            "  inflating: hololens/train/annotations/image (59).xml  \n",
            "  inflating: hololens/train/annotations/image (6).xml  \n",
            "  inflating: hololens/train/annotations/image (60).xml  \n",
            "  inflating: hololens/train/annotations/image (61).xml  \n",
            "  inflating: hololens/train/annotations/image (62).xml  \n",
            "  inflating: hololens/train/annotations/image (63).xml  \n",
            "  inflating: hololens/train/annotations/image (64).xml  \n",
            "  inflating: hololens/train/annotations/image (65).xml  \n",
            "  inflating: hololens/train/annotations/image (66).xml  \n",
            "  inflating: hololens/train/annotations/image (67).xml  \n",
            "  inflating: hololens/train/annotations/image (68).xml  \n",
            "  inflating: hololens/train/annotations/image (69).xml  \n",
            "  inflating: hololens/train/annotations/image (7).xml  \n",
            "  inflating: hololens/train/annotations/image (70).xml  \n",
            "  inflating: hololens/train/annotations/image (71).xml  \n",
            "  inflating: hololens/train/annotations/image (72).xml  \n",
            "  inflating: hololens/train/annotations/image (73).xml  \n",
            "  inflating: hololens/train/annotations/image (74).xml  \n",
            "  inflating: hololens/train/annotations/image (75).xml  \n",
            "  inflating: hololens/train/annotations/image (76).xml  \n",
            "  inflating: hololens/train/annotations/image (77).xml  \n",
            "  inflating: hololens/train/annotations/image (78).xml  \n",
            "  inflating: hololens/train/annotations/image (79).xml  \n",
            "  inflating: hololens/train/annotations/image (8).xml  \n",
            "  inflating: hololens/train/annotations/image (80).xml  \n",
            "  inflating: hololens/train/annotations/image (81).xml  \n",
            "  inflating: hololens/train/annotations/image (82).xml  \n",
            "  inflating: hololens/train/annotations/image (83).xml  \n",
            "  inflating: hololens/train/annotations/image (84).xml  \n",
            "  inflating: hololens/train/annotations/image (85).xml  \n",
            "  inflating: hololens/train/annotations/image (86).xml  \n",
            "  inflating: hololens/train/annotations/image (87).xml  \n",
            "  inflating: hololens/train/annotations/image (88).xml  \n",
            "  inflating: hololens/train/annotations/image (89).xml  \n",
            "  inflating: hololens/train/annotations/image (9).xml  \n",
            "  inflating: hololens/train/annotations/image (90).xml  \n",
            "  inflating: hololens/train/annotations/image (91).xml  \n",
            "  inflating: hololens/train/annotations/image (92).xml  \n",
            "  inflating: hololens/train/annotations/image (93).xml  \n",
            "  inflating: hololens/train/annotations/image (94).xml  \n",
            "  inflating: hololens/train/annotations/image (95).xml  \n",
            "  inflating: hololens/train/annotations/image (96).xml  \n",
            "  inflating: hololens/train/annotations/image (97).xml  \n",
            "  inflating: hololens/train/annotations/image (98).xml  \n",
            "  inflating: hololens/train/annotations/image (99).xml  \n",
            "   creating: hololens/train/images/\n",
            "  inflating: hololens/train/images/image (1).jpg  \n",
            "  inflating: hololens/train/images/image (10).jpg  \n",
            "  inflating: hololens/train/images/image (100).jpg  \n",
            "  inflating: hololens/train/images/image (101).jpg  \n",
            "  inflating: hololens/train/images/image (102).jpg  \n",
            "  inflating: hololens/train/images/image (103).jpg  \n",
            "  inflating: hololens/train/images/image (104).jpg  \n",
            "  inflating: hololens/train/images/image (105).jpg  \n",
            "  inflating: hololens/train/images/image (106).jpg  \n",
            "  inflating: hololens/train/images/image (107).jpg  \n",
            "  inflating: hololens/train/images/image (108).jpg  \n",
            "  inflating: hololens/train/images/image (109).jpg  \n",
            "  inflating: hololens/train/images/image (11).jpg  \n",
            "  inflating: hololens/train/images/image (110).jpg  \n",
            "  inflating: hololens/train/images/image (111).jpg  \n",
            "  inflating: hololens/train/images/image (112).jpg  \n",
            "  inflating: hololens/train/images/image (113).jpg  \n",
            "  inflating: hololens/train/images/image (114).jpg  \n",
            "  inflating: hololens/train/images/image (115).jpg  \n",
            "  inflating: hololens/train/images/image (116).jpg  \n",
            "  inflating: hololens/train/images/image (117).jpg  \n",
            "  inflating: hololens/train/images/image (118).jpg  \n",
            "  inflating: hololens/train/images/image (119).jpg  \n",
            "  inflating: hololens/train/images/image (12).jpg  \n",
            "  inflating: hololens/train/images/image (120).jpg  \n",
            "  inflating: hololens/train/images/image (121).jpg  \n",
            "  inflating: hololens/train/images/image (122).jpg  \n",
            "  inflating: hololens/train/images/image (123).jpg  \n",
            "  inflating: hololens/train/images/image (124).jpg  \n",
            "  inflating: hololens/train/images/image (125).jpg  \n",
            "  inflating: hololens/train/images/image (126).jpg  \n",
            "  inflating: hololens/train/images/image (127).jpg  \n",
            "  inflating: hololens/train/images/image (128).jpg  \n",
            "  inflating: hololens/train/images/image (129).jpg  \n",
            "  inflating: hololens/train/images/image (13).jpg  \n",
            "  inflating: hololens/train/images/image (130).jpg  \n",
            "  inflating: hololens/train/images/image (131).jpg  \n",
            "  inflating: hololens/train/images/image (132).jpg  \n",
            "  inflating: hololens/train/images/image (133).jpg  \n",
            "  inflating: hololens/train/images/image (134).jpg  \n",
            "  inflating: hololens/train/images/image (135).jpg  \n",
            "  inflating: hololens/train/images/image (136).jpg  \n",
            "  inflating: hololens/train/images/image (137).jpg  \n",
            "  inflating: hololens/train/images/image (138).jpg  \n",
            "  inflating: hololens/train/images/image (14).jpg  \n",
            "  inflating: hololens/train/images/image (140).jpg  \n",
            "  inflating: hololens/train/images/image (141).jpg  \n",
            "  inflating: hololens/train/images/image (142).jpg  \n",
            "  inflating: hololens/train/images/image (143).jpg  \n",
            "  inflating: hololens/train/images/image (144).jpg  \n",
            "  inflating: hololens/train/images/image (145).jpg  \n",
            "  inflating: hololens/train/images/image (146).jpg  \n",
            "  inflating: hololens/train/images/image (147).jpg  \n",
            "  inflating: hololens/train/images/image (148).jpg  \n",
            "  inflating: hololens/train/images/image (149).jpg  \n",
            "  inflating: hololens/train/images/image (15).jpg  \n",
            "  inflating: hololens/train/images/image (150).jpg  \n",
            "  inflating: hololens/train/images/image (151).jpg  \n",
            "  inflating: hololens/train/images/image (152).jpg  \n",
            "  inflating: hololens/train/images/image (153).jpg  \n",
            "  inflating: hololens/train/images/image (154).jpg  \n",
            "  inflating: hololens/train/images/image (155).jpg  \n",
            "  inflating: hololens/train/images/image (156).jpg  \n",
            "  inflating: hololens/train/images/image (157).jpg  \n",
            "  inflating: hololens/train/images/image (158).jpg  \n",
            "  inflating: hololens/train/images/image (159).jpg  \n",
            "  inflating: hololens/train/images/image (16).jpg  \n",
            "  inflating: hololens/train/images/image (160).jpg  \n",
            "  inflating: hololens/train/images/image (161).jpg  \n",
            "  inflating: hololens/train/images/image (162).jpg  \n",
            "  inflating: hololens/train/images/image (163).jpg  \n",
            "  inflating: hololens/train/images/image (164).jpg  \n",
            "  inflating: hololens/train/images/image (165).jpg  \n",
            "  inflating: hololens/train/images/image (166).jpg  \n",
            "  inflating: hololens/train/images/image (167).jpg  \n",
            "  inflating: hololens/train/images/image (168).jpg  \n",
            "  inflating: hololens/train/images/image (169).jpg  \n",
            "  inflating: hololens/train/images/image (17).jpg  \n",
            "  inflating: hololens/train/images/image (170).jpg  \n",
            "  inflating: hololens/train/images/image (171).jpg  \n",
            "  inflating: hololens/train/images/image (172).jpg  \n",
            "  inflating: hololens/train/images/image (173).jpg  \n",
            "  inflating: hololens/train/images/image (174).jpg  \n",
            "  inflating: hololens/train/images/image (175).jpg  \n",
            "  inflating: hololens/train/images/image (176).jpg  \n",
            "  inflating: hololens/train/images/image (177).jpg  \n",
            "  inflating: hololens/train/images/image (178).jpg  \n",
            "  inflating: hololens/train/images/image (179).jpg  \n",
            "  inflating: hololens/train/images/image (18).jpg  \n",
            "  inflating: hololens/train/images/image (180).jpg  \n",
            "  inflating: hololens/train/images/image (181).jpg  \n",
            "  inflating: hololens/train/images/image (182).jpg  \n",
            "  inflating: hololens/train/images/image (183).jpg  \n",
            "  inflating: hololens/train/images/image (184).jpg  \n",
            "  inflating: hololens/train/images/image (185).jpg  \n",
            "  inflating: hololens/train/images/image (186).jpg  \n",
            "  inflating: hololens/train/images/image (187).jpg  \n",
            "  inflating: hololens/train/images/image (188).jpg  \n",
            "  inflating: hololens/train/images/image (189).jpg  \n",
            "  inflating: hololens/train/images/image (19).jpg  \n",
            "  inflating: hololens/train/images/image (190).jpg  \n",
            "  inflating: hololens/train/images/image (191).jpg  \n",
            "  inflating: hololens/train/images/image (192).jpg  \n",
            "  inflating: hololens/train/images/image (193).jpg  \n",
            "  inflating: hololens/train/images/image (194).jpg  \n",
            "  inflating: hololens/train/images/image (195).jpg  \n",
            "  inflating: hololens/train/images/image (196).jpg  \n",
            "  inflating: hololens/train/images/image (197).jpg  \n",
            "  inflating: hololens/train/images/image (198).jpg  \n",
            "  inflating: hololens/train/images/image (199).jpg  \n",
            "  inflating: hololens/train/images/image (2).jpg  \n",
            "  inflating: hololens/train/images/image (20).jpg  \n",
            "  inflating: hololens/train/images/image (200).jpg  \n",
            "  inflating: hololens/train/images/image (201).jpg  \n",
            "  inflating: hololens/train/images/image (202).jpg  \n",
            "  inflating: hololens/train/images/image (203).jpg  \n",
            "  inflating: hololens/train/images/image (204).jpg  \n",
            "  inflating: hololens/train/images/image (205).jpg  \n",
            "  inflating: hololens/train/images/image (206).jpg  \n",
            "  inflating: hololens/train/images/image (207).jpg  \n",
            "  inflating: hololens/train/images/image (208).jpg  \n",
            "  inflating: hololens/train/images/image (209).jpg  \n",
            "  inflating: hololens/train/images/image (21).jpg  \n",
            "  inflating: hololens/train/images/image (210).jpg  \n",
            "  inflating: hololens/train/images/image (211).jpg  \n",
            "  inflating: hololens/train/images/image (212).jpg  \n",
            "  inflating: hololens/train/images/image (213).jpg  \n",
            "  inflating: hololens/train/images/image (214).jpg  \n",
            "  inflating: hololens/train/images/image (215).jpg  \n",
            "  inflating: hololens/train/images/image (216).jpg  \n",
            "  inflating: hololens/train/images/image (217).jpg  \n",
            "  inflating: hololens/train/images/image (218).jpg  \n",
            "  inflating: hololens/train/images/image (219).jpg  \n",
            "  inflating: hololens/train/images/image (22).jpg  \n",
            "  inflating: hololens/train/images/image (220).jpg  \n",
            "  inflating: hololens/train/images/image (221).jpg  \n",
            "  inflating: hololens/train/images/image (222).jpg  \n",
            "  inflating: hololens/train/images/image (223).jpg  \n",
            "  inflating: hololens/train/images/image (224).jpg  \n",
            "  inflating: hololens/train/images/image (225).jpg  \n",
            "  inflating: hololens/train/images/image (226).jpg  \n",
            "  inflating: hololens/train/images/image (227).jpg  \n",
            "  inflating: hololens/train/images/image (228).jpg  \n",
            "  inflating: hololens/train/images/image (229).jpg  \n",
            "  inflating: hololens/train/images/image (23).jpg  \n",
            "  inflating: hololens/train/images/image (230).jpg  \n",
            "  inflating: hololens/train/images/image (231).jpg  \n",
            "  inflating: hololens/train/images/image (232).jpg  \n",
            "  inflating: hololens/train/images/image (233).jpg  \n",
            "  inflating: hololens/train/images/image (234).jpg  \n",
            "  inflating: hololens/train/images/image (235).jpg  \n",
            "  inflating: hololens/train/images/image (236).jpg  \n",
            "  inflating: hololens/train/images/image (237).jpg  \n",
            "  inflating: hololens/train/images/image (238).jpg  \n",
            "  inflating: hololens/train/images/image (239).jpg  \n",
            "  inflating: hololens/train/images/image (24).jpg  \n",
            "  inflating: hololens/train/images/image (240).jpg  \n",
            "  inflating: hololens/train/images/image (241).jpg  \n",
            "  inflating: hololens/train/images/image (25).jpg  \n",
            "  inflating: hololens/train/images/image (26).jpg  \n",
            "  inflating: hololens/train/images/image (27).jpg  \n",
            "  inflating: hololens/train/images/image (28).jpg  \n",
            "  inflating: hololens/train/images/image (29).jpg  \n",
            "  inflating: hololens/train/images/image (3).jpg  \n",
            "  inflating: hololens/train/images/image (30).jpg  \n",
            "  inflating: hololens/train/images/image (31).jpg  \n",
            "  inflating: hololens/train/images/image (32).jpg  \n",
            "  inflating: hololens/train/images/image (33).jpg  \n",
            "  inflating: hololens/train/images/image (34).jpg  \n",
            "  inflating: hololens/train/images/image (35).jpg  \n",
            "  inflating: hololens/train/images/image (36).jpg  \n",
            "  inflating: hololens/train/images/image (37).jpg  \n",
            "  inflating: hololens/train/images/image (38).jpg  \n",
            "  inflating: hololens/train/images/image (39).jpg  \n",
            "  inflating: hololens/train/images/image (4).jpg  \n",
            "  inflating: hololens/train/images/image (40).jpg  \n",
            "  inflating: hololens/train/images/image (41).jpg  \n",
            "  inflating: hololens/train/images/image (42).jpg  \n",
            "  inflating: hololens/train/images/image (43).jpg  \n",
            "  inflating: hololens/train/images/image (44).jpg  \n",
            "  inflating: hololens/train/images/image (45).jpg  \n",
            "  inflating: hololens/train/images/image (46).jpg  \n",
            "  inflating: hololens/train/images/image (47).jpg  \n",
            "  inflating: hololens/train/images/image (48).jpg  \n",
            "  inflating: hololens/train/images/image (49).jpg  \n",
            "  inflating: hololens/train/images/image (5).jpg  \n",
            "  inflating: hololens/train/images/image (50).jpg  \n",
            "  inflating: hololens/train/images/image (51).jpg  \n",
            "  inflating: hololens/train/images/image (52).jpg  \n",
            "  inflating: hololens/train/images/image (53).jpg  \n",
            "  inflating: hololens/train/images/image (54).jpg  \n",
            "  inflating: hololens/train/images/image (55).jpg  \n",
            "  inflating: hololens/train/images/image (56).jpg  \n",
            "  inflating: hololens/train/images/image (57).jpg  \n",
            "  inflating: hololens/train/images/image (58).jpg  \n",
            "  inflating: hololens/train/images/image (59).jpg  \n",
            " extracting: hololens/train/images/image (6).jpg  \n",
            "  inflating: hololens/train/images/image (60).jpg  \n",
            "  inflating: hololens/train/images/image (61).jpg  \n",
            "  inflating: hololens/train/images/image (62).jpg  \n",
            "  inflating: hololens/train/images/image (63).jpg  \n",
            "  inflating: hololens/train/images/image (64).jpg  \n",
            "  inflating: hololens/train/images/image (65).jpg  \n",
            "  inflating: hololens/train/images/image (66).jpg  \n",
            "  inflating: hololens/train/images/image (67).jpg  \n",
            "  inflating: hololens/train/images/image (68).jpg  \n",
            "  inflating: hololens/train/images/image (69).jpg  \n",
            "  inflating: hololens/train/images/image (7).jpg  \n",
            "  inflating: hololens/train/images/image (70).jpg  \n",
            "  inflating: hololens/train/images/image (71).jpg  \n",
            "  inflating: hololens/train/images/image (72).jpg  \n",
            "  inflating: hololens/train/images/image (73).jpg  \n",
            "  inflating: hololens/train/images/image (74).jpg  \n",
            "  inflating: hololens/train/images/image (75).jpg  \n",
            "  inflating: hololens/train/images/image (76).jpg  \n",
            "  inflating: hololens/train/images/image (77).jpg  \n",
            "  inflating: hololens/train/images/image (78).jpg  \n",
            "  inflating: hololens/train/images/image (79).jpg  \n",
            "  inflating: hololens/train/images/image (8).jpg  \n",
            "  inflating: hololens/train/images/image (80).jpg  \n",
            "  inflating: hololens/train/images/image (81).jpg  \n",
            "  inflating: hololens/train/images/image (82).jpg  \n",
            "  inflating: hololens/train/images/image (83).jpg  \n",
            "  inflating: hololens/train/images/image (84).jpg  \n",
            "  inflating: hololens/train/images/image (85).jpg  \n",
            "  inflating: hololens/train/images/image (86).jpg  \n",
            "  inflating: hololens/train/images/image (87).jpg  \n",
            "  inflating: hololens/train/images/image (88).jpg  \n",
            "  inflating: hololens/train/images/image (89).jpg  \n",
            "  inflating: hololens/train/images/image (9).jpg  \n",
            "  inflating: hololens/train/images/image (90).jpg  \n",
            "  inflating: hololens/train/images/image (91).jpg  \n",
            "  inflating: hololens/train/images/image (92).jpg  \n",
            "  inflating: hololens/train/images/image (93).jpg  \n",
            "  inflating: hololens/train/images/image (94).jpg  \n",
            "  inflating: hololens/train/images/image (95).jpg  \n",
            "  inflating: hololens/train/images/image (96).jpg  \n",
            "  inflating: hololens/train/images/image (97).jpg  \n",
            "  inflating: hololens/train/images/image (98).jpg  \n",
            "  inflating: hololens/train/images/image (99).jpg  \n",
            "   creating: hololens/validation/\n",
            "   creating: hololens/validation/annotations/\n",
            "  inflating: hololens/validation/annotations/image (242).xml  \n",
            "  inflating: hololens/validation/annotations/image (243).xml  \n",
            "  inflating: hololens/validation/annotations/image (244).xml  \n",
            "  inflating: hololens/validation/annotations/image (245).xml  \n",
            "  inflating: hololens/validation/annotations/image (246).xml  \n",
            "  inflating: hololens/validation/annotations/image (247).xml  \n",
            "  inflating: hololens/validation/annotations/image (248).xml  \n",
            "  inflating: hololens/validation/annotations/image (249).xml  \n",
            "  inflating: hololens/validation/annotations/image (250).xml  \n",
            "  inflating: hololens/validation/annotations/image (251).xml  \n",
            "  inflating: hololens/validation/annotations/image (252).xml  \n",
            "  inflating: hololens/validation/annotations/image (253).xml  \n",
            "  inflating: hololens/validation/annotations/image (254).xml  \n",
            "  inflating: hololens/validation/annotations/image (255).xml  \n",
            "  inflating: hololens/validation/annotations/image (256).xml  \n",
            "  inflating: hololens/validation/annotations/image (257).xml  \n",
            "  inflating: hololens/validation/annotations/image (258).xml  \n",
            "  inflating: hololens/validation/annotations/image (259).xml  \n",
            "  inflating: hololens/validation/annotations/image (260).xml  \n",
            "  inflating: hololens/validation/annotations/image (261).xml  \n",
            "  inflating: hololens/validation/annotations/image (262).xml  \n",
            "  inflating: hololens/validation/annotations/image (263).xml  \n",
            "  inflating: hololens/validation/annotations/image (264).xml  \n",
            "  inflating: hololens/validation/annotations/image (265).xml  \n",
            "  inflating: hololens/validation/annotations/image (266).xml  \n",
            "  inflating: hololens/validation/annotations/image (267).xml  \n",
            "  inflating: hololens/validation/annotations/image (268).xml  \n",
            "  inflating: hololens/validation/annotations/image (269).xml  \n",
            "  inflating: hololens/validation/annotations/image (270).xml  \n",
            "  inflating: hololens/validation/annotations/image (271).xml  \n",
            "  inflating: hololens/validation/annotations/image (272).xml  \n",
            "  inflating: hololens/validation/annotations/image (273).xml  \n",
            "  inflating: hololens/validation/annotations/image (274).xml  \n",
            "  inflating: hololens/validation/annotations/image (275).xml  \n",
            "  inflating: hololens/validation/annotations/image (276).xml  \n",
            "  inflating: hololens/validation/annotations/image (277).xml  \n",
            "  inflating: hololens/validation/annotations/image (278).xml  \n",
            "  inflating: hololens/validation/annotations/image (279).xml  \n",
            "  inflating: hololens/validation/annotations/image (280).xml  \n",
            "  inflating: hololens/validation/annotations/image (281).xml  \n",
            "  inflating: hololens/validation/annotations/image (282).xml  \n",
            "  inflating: hololens/validation/annotations/image (283).xml  \n",
            "  inflating: hololens/validation/annotations/image (284).xml  \n",
            "  inflating: hololens/validation/annotations/image (285).xml  \n",
            "  inflating: hololens/validation/annotations/image (286).xml  \n",
            "  inflating: hololens/validation/annotations/image (287).xml  \n",
            "  inflating: hololens/validation/annotations/image (288).xml  \n",
            "  inflating: hololens/validation/annotations/image (289).xml  \n",
            "  inflating: hololens/validation/annotations/image (290).xml  \n",
            "  inflating: hololens/validation/annotations/image (291).xml  \n",
            "  inflating: hololens/validation/annotations/image (292).xml  \n",
            "  inflating: hololens/validation/annotations/image (293).xml  \n",
            "  inflating: hololens/validation/annotations/image (294).xml  \n",
            "  inflating: hololens/validation/annotations/image (295).xml  \n",
            "  inflating: hololens/validation/annotations/image (296).xml  \n",
            "  inflating: hololens/validation/annotations/image (297).xml  \n",
            "  inflating: hololens/validation/annotations/image (298).xml  \n",
            "  inflating: hololens/validation/annotations/image (299).xml  \n",
            "  inflating: hololens/validation/annotations/image (300).xml  \n",
            "   creating: hololens/validation/images/\n",
            "  inflating: hololens/validation/images/image (242).jpg  \n",
            "  inflating: hololens/validation/images/image (243).jpg  \n",
            "  inflating: hololens/validation/images/image (244).jpg  \n",
            "  inflating: hololens/validation/images/image (245).jpg  \n",
            "  inflating: hololens/validation/images/image (246).jpg  \n",
            "  inflating: hololens/validation/images/image (247).jpg  \n",
            "  inflating: hololens/validation/images/image (248).jpg  \n",
            "  inflating: hololens/validation/images/image (249).jpg  \n",
            "  inflating: hololens/validation/images/image (250).jpg  \n",
            "  inflating: hololens/validation/images/image (251).jpg  \n",
            "  inflating: hololens/validation/images/image (252).jpg  \n",
            "  inflating: hololens/validation/images/image (253).jpg  \n",
            "  inflating: hololens/validation/images/image (254).jpg  \n",
            "  inflating: hololens/validation/images/image (255).jpg  \n",
            "  inflating: hololens/validation/images/image (256).jpg  \n",
            "  inflating: hololens/validation/images/image (257).jpg  \n",
            "  inflating: hololens/validation/images/image (258).jpg  \n",
            "  inflating: hololens/validation/images/image (259).jpg  \n",
            "  inflating: hololens/validation/images/image (260).jpg  \n",
            "  inflating: hololens/validation/images/image (261).jpg  \n",
            "  inflating: hololens/validation/images/image (262).jpg  \n",
            "  inflating: hololens/validation/images/image (263).jpg  \n",
            "  inflating: hololens/validation/images/image (264).jpg  \n",
            "  inflating: hololens/validation/images/image (265).jpg  \n",
            "  inflating: hololens/validation/images/image (266).jpg  \n",
            "  inflating: hololens/validation/images/image (267).jpg  \n",
            "  inflating: hololens/validation/images/image (268).jpg  \n",
            "  inflating: hololens/validation/images/image (269).jpg  \n",
            "  inflating: hololens/validation/images/image (270).jpg  \n",
            "  inflating: hololens/validation/images/image (271).jpg  \n",
            "  inflating: hololens/validation/images/image (272).jpg  \n",
            "  inflating: hololens/validation/images/image (273).jpg  \n",
            "  inflating: hololens/validation/images/image (274).jpg  \n",
            "  inflating: hololens/validation/images/image (275).jpg  \n",
            "  inflating: hololens/validation/images/image (276).jpg  \n",
            "  inflating: hololens/validation/images/image (277).jpg  \n",
            "  inflating: hololens/validation/images/image (278).jpg  \n",
            "  inflating: hololens/validation/images/image (279).jpg  \n",
            "  inflating: hololens/validation/images/image (280).jpg  \n",
            "  inflating: hololens/validation/images/image (281).jpg  \n",
            "  inflating: hololens/validation/images/image (282).jpg  \n",
            "  inflating: hololens/validation/images/image (283).jpg  \n",
            "  inflating: hololens/validation/images/image (284).jpg  \n",
            "  inflating: hololens/validation/images/image (285).jpg  \n",
            "  inflating: hololens/validation/images/image (286).jpg  \n",
            "  inflating: hololens/validation/images/image (287).jpg  \n",
            "  inflating: hololens/validation/images/image (288).jpg  \n",
            "  inflating: hololens/validation/images/image (289).jpg  \n",
            "  inflating: hololens/validation/images/image (290).jpg  \n",
            "  inflating: hololens/validation/images/image (291).jpg  \n",
            "  inflating: hololens/validation/images/image (292).jpg  \n",
            "  inflating: hololens/validation/images/image (293).jpg  \n",
            "  inflating: hololens/validation/images/image (294).jpg  \n",
            "  inflating: hololens/validation/images/image (295).jpg  \n",
            "  inflating: hololens/validation/images/image (296).jpg  \n",
            "  inflating: hololens/validation/images/image (297).jpg  \n",
            "  inflating: hololens/validation/images/image (298).jpg  \n",
            "  inflating: hololens/validation/images/image (299).jpg  \n",
            "  inflating: hololens/validation/images/image (300).jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOG_vtA8NcjT"
      },
      "source": [
        "## 3. Optional: Download a pretrain model\n",
        "If we have a pretrain model, we could use transfer learning and then speed up the traing procedure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZshF2e2tKTDq"
      },
      "source": [
        "# !wget https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/pretrained-yolov3.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kb60dJKJlwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "436b135e-db7b-4c33-d42c-7316ebf54bc9"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mhololens\u001b[0m/  hololens.zip  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSIkmq2hNjcj"
      },
      "source": [
        "## 4. Start the trainning now\n",
        "The first experiment takes 360 to 669 seconds (depended on the batch size you set). The next step spends 300 to 405 seconds. If we use 200 epochs, we roughly needs 22 hours. Please note that we download a pretrain model in the program."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws3nDbtmJc7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a2278b3-2bf0-4e62-fee4-1c57786b6f05"
      },
      "source": [
        "from imageai.Detection.Custom import DetectionModelTrainer\n",
        "\n",
        "trainer = DetectionModelTrainer()\n",
        "trainer.setModelTypeAsYOLOv3()\n",
        "trainer.setDataDirectory(data_directory=\"hololens\")\n",
        "# trainer.setTrainConfig(object_names_array=[\"hololens\"], batch_size=8, num_experiments=5, train_from_pretrained_model=\"pretrained-yolov3.h5\")\n",
        "trainer.setTrainConfig(object_names_array=[\"hololens\"], batch_size=8, num_experiments=5)\n",
        "trainer.trainModel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating anchor boxes for training images and annotation...\n",
            "Average IOU for 9 anchors: 0.78\n",
            "Anchor Boxes generated.\n",
            "Detection configuration saved in  hololens/json/detection_config.json\n",
            "Evaluating over 59 samples taken from hololens/validation\n",
            "Training over 240 samples  given at hololens/train\n",
            "Training on: \t['hololens']\n",
            "Training with Batch Size:  8\n",
            "Number of Training Samples:  240\n",
            "Number of Validation Samples:  59\n",
            "Number of Experiments:  5\n",
            "Pre-trained Model not provided. Transfer learning not in use.\n",
            "Training will start with 3 warmup experiments\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer YoloLayer has arguments in `__init__` and therefore must override `get_config`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "240/240 [==============================] - 457s 2s/step - loss: 333.7047 - yolo_layer_loss: 40.9297 - yolo_layer_1_loss: 82.1514 - yolo_layer_2_loss: 199.0623 - val_loss: 83.9382 - val_yolo_layer_loss: 10.1703 - val_yolo_layer_1_loss: 16.9094 - val_yolo_layer_2_loss: 45.4455\n",
            "Epoch 2/8\n",
            "240/240 [==============================] - 418s 2s/step - loss: 57.5425 - yolo_layer_loss: 7.9981 - yolo_layer_1_loss: 12.6741 - yolo_layer_2_loss: 25.5884 - val_loss: 51.7556 - val_yolo_layer_loss: 9.1656 - val_yolo_layer_1_loss: 11.5239 - val_yolo_layer_2_loss: 20.3420\n",
            "Epoch 3/8\n",
            "240/240 [==============================] - 404s 2s/step - loss: 44.8203 - yolo_layer_loss: 6.7259 - yolo_layer_1_loss: 11.0468 - yolo_layer_2_loss: 16.5425 - val_loss: 68.8719 - val_yolo_layer_loss: 19.3298 - val_yolo_layer_1_loss: 13.3939 - val_yolo_layer_2_loss: 26.3268\n",
            "Epoch 4/8\n",
            "240/240 [==============================] - 387s 2s/step - loss: 40.1421 - yolo_layer_loss: 6.0602 - yolo_layer_1_loss: 10.6163 - yolo_layer_2_loss: 13.8948 - val_loss: 54.9491 - val_yolo_layer_loss: 10.4026 - val_yolo_layer_1_loss: 12.0021 - val_yolo_layer_2_loss: 23.7319\n",
            "Epoch 5/8\n",
            "240/240 [==============================] - 407s 2s/step - loss: 37.1017 - yolo_layer_loss: 5.7931 - yolo_layer_1_loss: 10.2039 - yolo_layer_2_loss: 12.5108 - val_loss: 102.7472 - val_yolo_layer_loss: 10.9902 - val_yolo_layer_1_loss: 12.9710 - val_yolo_layer_2_loss: 70.6898\n",
            "Epoch 6/8\n",
            "240/240 [==============================] - 402s 2s/step - loss: 35.9823 - yolo_layer_loss: 5.8529 - yolo_layer_1_loss: 10.4095 - yolo_layer_2_loss: 11.7540 - val_loss: 71.6073 - val_yolo_layer_loss: 13.9916 - val_yolo_layer_1_loss: 14.9281 - val_yolo_layer_2_loss: 35.0825\n",
            "Epoch 7/8\n",
            "240/240 [==============================] - 422s 2s/step - loss: 34.4082 - yolo_layer_loss: 5.9201 - yolo_layer_1_loss: 9.4934 - yolo_layer_2_loss: 11.4834 - val_loss: 37.1819 - val_yolo_layer_loss: 8.1500 - val_yolo_layer_1_loss: 10.2319 - val_yolo_layer_2_loss: 11.5308\n",
            "Epoch 8/8\n",
            "240/240 [==============================] - 388s 2s/step - loss: 33.0922 - yolo_layer_loss: 5.8009 - yolo_layer_1_loss: 8.7568 - yolo_layer_2_loss: 11.3407 - val_loss: 59.1129 - val_yolo_layer_loss: 8.1846 - val_yolo_layer_1_loss: 11.6497 - val_yolo_layer_2_loss: 32.2781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMI1lb8uMhDP"
      },
      "source": [
        "## 5. Model Evaluation\n",
        "It shows the mAP of our trained models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcFoyICQMjVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75452e53-8714-40e3-b0dc-4775a6e7afd0"
      },
      "source": [
        "from imageai.Detection.Custom import DetectionModelTrainer\n",
        "\n",
        "trainer = DetectionModelTrainer()\n",
        "trainer.setModelTypeAsYOLOv3()\n",
        "trainer.setDataDirectory(data_directory=\"hololens\")\n",
        "trainer.evaluateModel(model_path=\"hololens/models\", json_path=\"hololens/json/detection_config.json\", iou_threshold=0.5, object_threshold=0.3, nms_threshold=0.5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Model evaluation....\n",
            "Evaluating over 59 samples taken from hololens/validation\n",
            "Training over 240 samples  given at hololens/train\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model File:  hololens/models/detection_model-ex-001--loss-0166.903.h5 \n",
            "\n",
            "Evaluation samples:  59\n",
            "Using IoU:  0.5\n",
            "Using Object Threshold:  0.3\n",
            "Using Non-Maximum Suppression:  0.5\n",
            "hololens: 0.0000\n",
            "mAP: 0.0000\n",
            "===============================\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model File:  hololens/models/detection_model-ex-002--loss-0052.358.h5 \n",
            "\n",
            "Evaluation samples:  59\n",
            "Using IoU:  0.5\n",
            "Using Object Threshold:  0.3\n",
            "Using Non-Maximum Suppression:  0.5\n",
            "hololens: 0.0220\n",
            "mAP: 0.0220\n",
            "===============================\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model File:  hololens/models/detection_model-ex-003--loss-0043.399.h5 \n",
            "\n",
            "Evaluation samples:  59\n",
            "Using IoU:  0.5\n",
            "Using Object Threshold:  0.3\n",
            "Using Non-Maximum Suppression:  0.5\n",
            "hololens: 0.0000\n",
            "mAP: 0.0000\n",
            "===============================\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model File:  hololens/models/detection_model-ex-004--loss-0039.054.h5 \n",
            "\n",
            "Evaluation samples:  59\n",
            "Using IoU:  0.5\n",
            "Using Object Threshold:  0.3\n",
            "Using Non-Maximum Suppression:  0.5\n",
            "hololens: 0.0001\n",
            "mAP: 0.0001\n",
            "===============================\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model File:  hololens/models/detection_model-ex-005--loss-0037.319.h5 \n",
            "\n",
            "Evaluation samples:  59\n",
            "Using IoU:  0.5\n",
            "Using Object Threshold:  0.3\n",
            "Using Non-Maximum Suppression:  0.5\n",
            "hololens: 0.0377\n",
            "mAP: 0.0377\n",
            "===============================\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model File:  hololens/models/detection_model-ex-006--loss-0035.551.h5 \n",
            "\n",
            "Evaluation samples:  59\n",
            "Using IoU:  0.5\n",
            "Using Object Threshold:  0.3\n",
            "Using Non-Maximum Suppression:  0.5\n",
            "hololens: 0.0282\n",
            "mAP: 0.0282\n",
            "===============================\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model File:  hololens/models/detection_model-ex-007--loss-0034.230.h5 \n",
            "\n",
            "Evaluation samples:  59\n",
            "Using IoU:  0.5\n",
            "Using Object Threshold:  0.3\n",
            "Using Non-Maximum Suppression:  0.5\n",
            "hololens: 0.1399\n",
            "mAP: 0.1399\n",
            "===============================\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model File:  hololens/models/detection_model-ex-008--loss-0032.534.h5 \n",
            "\n",
            "Evaluation samples:  59\n",
            "Using IoU:  0.5\n",
            "Using Object Threshold:  0.3\n",
            "Using Non-Maximum Suppression:  0.5\n",
            "hololens: 0.2084\n",
            "mAP: 0.2084\n",
            "===============================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'average_precision': {'hololens': 0.0},\n",
              "  'evaluation_samples': 59,\n",
              "  'map': 0.0,\n",
              "  'model_file': 'hololens/models/detection_model-ex-001--loss-0166.903.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3},\n",
              " {'average_precision': {'hololens': 0.022003695650970916},\n",
              "  'evaluation_samples': 59,\n",
              "  'map': 0.022003695650970916,\n",
              "  'model_file': 'hololens/models/detection_model-ex-002--loss-0052.358.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3},\n",
              " {'average_precision': {'hololens': 0.0},\n",
              "  'evaluation_samples': 59,\n",
              "  'map': 0.0,\n",
              "  'model_file': 'hololens/models/detection_model-ex-003--loss-0043.399.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3},\n",
              " {'average_precision': {'hololens': 0.00010989010989010989},\n",
              "  'evaluation_samples': 59,\n",
              "  'map': 0.00010989010989010989,\n",
              "  'model_file': 'hololens/models/detection_model-ex-004--loss-0039.054.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3},\n",
              " {'average_precision': {'hololens': 0.03765241227617589},\n",
              "  'evaluation_samples': 59,\n",
              "  'map': 0.03765241227617589,\n",
              "  'model_file': 'hololens/models/detection_model-ex-005--loss-0037.319.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3},\n",
              " {'average_precision': {'hololens': 0.028191342812343118},\n",
              "  'evaluation_samples': 59,\n",
              "  'map': 0.028191342812343118,\n",
              "  'model_file': 'hololens/models/detection_model-ex-006--loss-0035.551.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3},\n",
              " {'average_precision': {'hololens': 0.13989406968477644},\n",
              "  'evaluation_samples': 59,\n",
              "  'map': 0.13989406968477644,\n",
              "  'model_file': 'hololens/models/detection_model-ex-007--loss-0034.230.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3},\n",
              " {'average_precision': {'hololens': 0.20841493609470033},\n",
              "  'evaluation_samples': 59,\n",
              "  'map': 0.20841493609470033,\n",
              "  'model_file': 'hololens/models/detection_model-ex-008--loss-0032.534.h5',\n",
              "  'using_iou': 0.5,\n",
              "  'using_non_maximum_suppression': 0.5,\n",
              "  'using_object_threshold': 0.3}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mmthG-_N1Qp"
      },
      "source": [
        "## 6. Testing the trained model\n",
        "We should select a trained model manually. However, in order to let the program to be ran without any modification, we use the model instead. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4dzRKBrSmu1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc6123f5-69d1-498f-9e3c-eea98b56e663"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "list_of_files = glob.glob('hololens/models/*') # * means all if need specific format then *.csv\n",
        "latest_model = max(list_of_files, key=os.path.getctime)\n",
        "print(latest_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hololens/models/detection_model-ex-008--loss-0032.534.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yg89M2_4ngUb"
      },
      "source": [
        "Download a testing figure from internet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTgYye1wLcNe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6d1d653-718b-41c2-bc59-1a63f60938e8"
      },
      "source": [
        "!wget https://mspoweruser.com/wp-content/uploads/2018/10/hololens-festival.jpg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-19 12:41:44--  https://mspoweruser.com/wp-content/uploads/2018/10/hololens-festival.jpg\n",
            "Resolving mspoweruser.com (mspoweruser.com)... 172.67.98.25, 104.25.148.15, 104.25.149.15, ...\n",
            "Connecting to mspoweruser.com (mspoweruser.com)|172.67.98.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 142512 (139K) [image/jpeg]\n",
            "Saving to: ‘hololens-festival.jpg’\n",
            "\n",
            "hololens-festival.j 100%[===================>] 139.17K   710KB/s    in 0.2s    \n",
            "\n",
            "2021-01-19 12:41:46 (710 KB/s) - ‘hololens-festival.jpg’ saved [142512/142512]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAyxHNySUB1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f8bf133-a6a4-4f3a-dea3-bbd7dbda54a7"
      },
      "source": [
        "from imageai.Detection.Custom import CustomObjectDetection\n",
        "\n",
        "detector = CustomObjectDetection()\n",
        "detector.setModelTypeAsYOLOv3()\n",
        "detector.setModelPath(latest_model)\n",
        "detector.setJsonPath(\"hololens/json/detection_config.json\")\n",
        "detector.loadModel()\n",
        "detections = detector.detectObjectsFromImage(input_image=\"hololens-festival.jpg\", output_image_path=\"holo2-detected.jpg\")\n",
        "for detection in detections:\n",
        "    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}