{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ujw4bwTRUjnN"
      },
      "source": [
        "# 主題 01-3. 作業: 改造你的 1 號神經網路\n",
        "\n",
        "本週的作業很簡單, 就是把上課手寫辨識的範例改造一下, 看能不能讓成效變得更好。因為是第一次作業, 我們不特別要求要達到什麼水準, 只要「測試資料」的正確率還在 9 成以上就可以。我們這美好的 MNIST 例子, 你基本上亂亂作都是可以達成的, 不用擔心!\n",
        "\n",
        "【註】因 TensorFlow 2 已做了一些改變, 例如完全整合了 Keras。到 2021 年的今天, 有一些細節也做了調整。因此我們依新的規範修改了程式。最大的不同是, 以後大家直接安裝 tensorflow 即可, 不用再另外裝 keras。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHOXuLsIUjnR"
      },
      "source": [
        "## 1. 初始準備\n",
        "\n",
        "這裡是一樣的我們不再說明。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0FMTesnUjnS"
      },
      "source": [
        "再來是我們標準數據分析動作!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JRvzhBy1UjnS"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kyBJFm2UjnU"
      },
      "source": [
        "## 2. 讀入 MNIST 數據庫"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "HBwhxfwSUjnU"
      },
      "source": [
        "這裡也是一樣的! 好消息是如果你之前跟著做過, 現在會快很多。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "djz1LFccUjnU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "w33PAt6XUjnV",
        "outputId": "25ae4e49-430d-4e3d-dfb4-a17457c55571",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2bI4p62UjnW"
      },
      "source": [
        "## 3. 改造你的神經網路\n",
        "\n",
        "### 3.1 改變結構\n",
        "\n",
        "我們本來用了兩層的隱藏層, 你可以改不同層數試試。比方說, 你可以試真的「深度學習」, 也就是隱藏層加到 3 層或以上。不過你需要有電腦彷如當機的心理準備...\n",
        "\n",
        "另外也可改變神經元的數目。比如說本來是這樣設的一個隱藏層, 我們用了 500 個神經元是這樣寫的。\n",
        "\n",
        "    model.add(Dense(500))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    \n",
        "因此如果要改 520 個神經元, 就會像這樣:\n",
        "\n",
        "    model.add(Dense(520))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    \n",
        "是不是很簡單?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oqr6mnOKUjnW"
      },
      "source": [
        "### 3.2 換個 activation function!\n",
        "\n",
        "在 Keras 中要換個 activation function 很簡單, 比如說我們要換當巨星 ReLU, 就在每層設 activation function 時說就好了。\n",
        "\n",
        "    model.add(Dense(500))\n",
        "    model.add(Activation('relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOi4jth3UjnX"
      },
      "source": [
        "## 4. Normalize 我們的數據\n",
        "\n",
        "我們的每筆輸入是 784 維的\n",
        "\n",
        "$$\\mathbf{x} = (x_1, x_2, \\ldots, x_{784})$$\n",
        "\n",
        "我們會說這個神經網路有 784 個 features。現在我們每一個 $x_i$ 都是 0 到 255 的整數, 我們常喜歡把每個 $x_i$ 壓縮到一個更小的範圍, 一般有兩種作法:\n",
        "\n",
        "1. 每個 $x_i$ 都壓到 [0,1] 中的一個數\n",
        "2. 讓每個 $x_i$ 由平均值是 0, 標準差是 1 的"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4p-mVanUjnX"
      },
      "source": [
        "我們的例子來做做看!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rKqEYgEKUjnX"
      },
      "outputs": [],
      "source": [
        "x_train = x_train/255\n",
        "x_test = x_test/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAKyFO7HUjnY"
      },
      "source": [
        "可以試試看就知道, 真的都壓到 0-1 之間的數。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Hh_ijUV6UjnY"
      },
      "outputs": [],
      "source": [
        "# x_train[87]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMz6GbdVUjnY"
      },
      "source": [
        "還是可以畫的哦! 指令和以前完全一樣!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ga0U5tVGUjnY",
        "outputId": "665eecca-a15c-43ba-a466-9644e3c7eb5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdaf50e9fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOOElEQVR4nO3df4xV9ZnH8c+j0qBDVVgmhFAiXUSjblxKRlyFEI1KBEmw8VeJVjZRhz8ktrF/rHFJauKP6Lql4Y9NdRAsxS61EYkkErcuQUxj0jggi6DuiooBZJghmEAlpPx49o85NFOc8z3DPef+gOf9Sib33vOcc8/DCZ85d8733vs1dxeAs985zW4AQGMQdiAIwg4EQdiBIAg7EMR5jdzZ6NGjfcKECY3cJRDKzp07tX//fhusVirsZnarpCWSzpX0krs/m1p/woQJ6u7uLrNLAAkdHR25tZpfxpvZuZL+Q9IsSVdKmmdmV9b6fADqq8zf7FMl7XD3z939L5J+J2luNW0BqFqZsI+TtGvA493Zsr9hZp1m1m1m3X19fSV2B6CMul+Nd/cud+9w94729vZ67w5AjjJh3yNp/IDH38uWAWhBZcL+vqRJZvZ9M/uOpB9JWltNWwCqVvPQm7sfM7OFkv5L/UNvy919e2WdAahUqXF2d18naV1FvQCoI94uCwRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQii1JTNZrZT0iFJxyUdc/eOKpoCUL1SYc/c6O77K3geAHXEy3ggiLJhd0l/MLNNZtY52Apm1mlm3WbW3dfXV3J3AGpVNuzT3X2KpFmSHjazGaeu4O5d7t7h7h3t7e0ldwegVqXC7u57stteSWskTa2iKQDVqznsZtZmZt89eV/STEnbqmoMQLXKXI0fI2mNmZ18nv9097cq6QpA5WoOu7t/LukfK+wFQB0x9AYEQdiBIAg7EARhB4Ig7EAQVXwQBi2s6C3Ka9asSdafe+65ZP2LL7447Z5OcvdkPRvWzbVgwYJkfdGiRbm1cePGJbc9G3FmB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgGGc/A/T09CTrH3zwQW5t7ty5yW2PHz9eU08nFY2F12tbSerq6krWly1blltbuHBhctvFixfX1FMr48wOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0Ewzt4CNmzYkKzPmTMnWU99LrzsOPqsWbOS9e3btyfrTz31VG7t+uuvT2576aWXJutFUv/2VatWJbdlnB3AGYuwA0EQdiAIwg4EQdiBIAg7EARhB4JgnL0FrF+/Plk/cuRIzc997733Jusvvvhisn7eeen/IkXj+MOHD8+tnThxIrntZ599lqxPnDgxWU+58847a972TFV4Zjez5WbWa2bbBiwbZWZvm9mn2e3I+rYJoKyhvIz/taRbT1n2mKT17j5J0vrsMYAWVhh2d39X0oFTFs+VtCK7v0LS7dW2BaBqtV6gG+Pue7P7PZLG5K1oZp1m1m1m3UXzjgGon9JX473/Uxi5n8Rw9y5373D3jvb29rK7A1CjWsO+z8zGSlJ221tdSwDqodawr5U0P7s/X9Ib1bQDoF4Kx9nNbJWkGySNNrPdkn4u6VlJvzezByR9KenuejZ5puvtTb/weeGFF+q27+nTpyfr559/fqnnHzZsWLJ++PDh3Nr8+fNza5L03nvv1dTTUEydOrVuz92qCsPu7vNySjdV3AuAOuLtskAQhB0IgrADQRB2IAjCDgTBR1wb4MYbb0zWv/7662T98ssvT9Zvvvnm3Npdd92V3Hbjxo3J+jXXXJOs79+/P1mfMWNGbm3Xrl3JbYtceOGFyfpbb72VW5s8eXKpfZ+JOLMDQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCMs1egaKz5q6++StY7OzuT9eeffz5ZP+ec/N/ZRV8FfdFFFyXr33zzTbJ+9OjRZL3sWHrK0qVLk/Vrr722bvs+E3FmB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgGGevQNGUywcPHkzWX3/99WT9kUceSdavuOKKZD2l7Oe6N23aVGr7lMsuuyxZnzNnTt32fTbizA4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQTDOXoGi8d6LL744WS/6PHzR985fddVVubXbbrut5m0l6bXXXkvWV69enayX8eSTTybrw4cPr9u+z0aFZ3YzW25mvWa2bcCyJ8xsj5ltyX5m17dNAGUN5WX8ryXdOsjyX7r75OxnXbVtAahaYdjd/V1JBxrQC4A6KnOBbqGZbc1e5o/MW8nMOs2s28y6+/r6SuwOQBm1hv1XkiZKmixpr6Rf5K3o7l3u3uHuHe3t7TXuDkBZNYXd3fe5+3F3PyFpqaSp1bYFoGo1hd3Mxg54+ENJ2/LWBdAaCsfZzWyVpBskjTaz3ZJ+LukGM5ssySXtlLSgfi22vra2tmR98+bNyfpDDz2UrBd9Xv6dd96pqdZsRfOrX3311Q3qJIbCsLv7vEEWL6tDLwDqiLfLAkEQdiAIwg4EQdiBIAg7EAQfcW2ASy65JFkv+irpN998M1l/8MEHc2uHDx9Objtq1Khk/dFHH03WFy1alKyndHV1JetFXyWN08OZHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCYJy9BYwYMSJZv+eee5L1KVOm5NaOHDmS3Lboa66XLFmSrBe54447cmuzZ/OlxI3EmR0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgmCc/SwwadKk3FrROPszzzyTrK9cuTJZT43xS9LLL7+cWyv6Cm5UizM7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgTBOPtZbuPGjcn6008/nawXjYUXjdMzlt46Cs/sZjbezDaY2Udmtt3MfpItH2Vmb5vZp9ntyPq3C6BWQ3kZf0zSz9z9Skn/JOlhM7tS0mOS1rv7JEnrs8cAWlRh2N19r7tvzu4fkvSxpHGS5kpaka22QtLtdeoRQAVO6wKdmU2Q9ANJf5I0xt33ZqUeSWNytuk0s24z6+7r6yvTK4AShhx2MxshabWkn7r7wYE1d3dJPth27t7l7h3u3tHe3l6qWQC1G1LYzWyY+oP+W3c/OeXoPjMbm9XHSuqtT4sAqlA49GZmJmmZpI/dffGA0lpJ8yU9m92+UZcOUWjr1q25tfvuu6/Uc7/yyivJ+i233FLq+dE4Qxlnnybpx5I+NLMt2bLH1R/y35vZA5K+lHR3XToEUInCsLv7HyVZTvmmatsBUC+8XRYIgrADQRB2IAjCDgRB2IEg+IjrGeDo0aPJ+rx583JrBw4cSG5bNG3yTTcx4HK24MwOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0Ewzt4Cjh07lqwvXLgwWf/kk09ya9ddd11y21dffTVZv+CCC5J1nDk4swNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIyzt4B169Yl6y+99FKyPnPmzNxa0ZTKjKPHwZkdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4IYyvzs4yX9RtIYSS6py92XmNkTkh6S1Jet+ri7pweMg9qxY0eyfv/995d6/pUrV+bWRo8eXeq5cfYYyptqjkn6mbtvNrPvStpkZm9ntV+6+7/Xrz0AVRnK/Ox7Je3N7h8ys48ljat3YwCqdVp/s5vZBEk/kPSnbNFCM9tqZsvNbGTONp1m1m1m3X19fYOtAqABhhx2MxshabWkn7r7QUm/kjRR0mT1n/l/Mdh27t7l7h3u3tHe3l6+YwA1GVLYzWyY+oP+W3d/XZLcfZ+7H3f3E5KWSppavzYBlFUYdjMzScskfezuiwcsHztgtR9K2lZ9ewCqMpSr8dMk/VjSh2a2JVv2uKR5ZjZZ/cNxOyUtqEN/Z4Xp06cn64cOHUrWp02blqy3tbWddk+IZyhX4/8oyQYpMaYOnEF4Bx0QBGEHgiDsQBCEHQiCsANBEHYgCL5KugF6enqa3QLAmR2IgrADQRB2IAjCDgRB2IEgCDsQBGEHgjB3b9zOzPokfTlg0WhJ+xvWwOlp1d5atS+J3mpVZW+XuPug3//W0LB/a+dm3e7e0bQGElq1t1btS6K3WjWqN17GA0EQdiCIZoe9q8n7T2nV3lq1L4neatWQ3pr6NzuAxmn2mR1AgxB2IIimhN3MbjWz/zWzHWb2WDN6yGNmO83sQzPbYmbdTe5luZn1mtm2ActGmdnbZvZpdjvoHHtN6u0JM9uTHbstZja7Sb2NN7MNZvaRmW03s59ky5t67BJ9NeS4NfxvdjM7V9L/SbpF0m5J70ua5+4fNbSRHGa2U1KHuzf9DRhmNkPSnyX9xt3/IVv2b5IOuPuz2S/Kke7+Ly3S2xOS/tzsabyz2YrGDpxmXNLtkv5ZTTx2ib7uVgOOWzPO7FMl7XD3z939L5J+J2luE/poee7+rqQDpyyeK2lFdn+F+v+zNFxOby3B3fe6++bs/iFJJ6cZb+qxS/TVEM0I+zhJuwY83q3Wmu/dJf3BzDaZWWezmxnEGHffm93vkTSmmc0MonAa70Y6ZZrxljl2tUx/XhYX6L5turtPkTRL0sPZy9WW5P1/g7XS2OmQpvFulEGmGf+rZh67Wqc/L6sZYd8jafyAx9/LlrUEd9+T3fZKWqPWm4p638kZdLPb3ib381etNI33YNOMqwWOXTOnP29G2N+XNMnMvm9m35H0I0lrm9DHt5hZW3bhRGbWJmmmWm8q6rWS5mf350t6o4m9/I1WmcY7b5pxNfnYNX36c3dv+I+k2eq/Iv+ZpH9tRg85ff29pP/JfrY3uzdJq9T/su6o+q9tPCDp7yStl/SppP+WNKqFelsp6UNJW9UfrLFN6m26+l+ib5W0JfuZ3exjl+irIceNt8sCQXCBDgiCsANBEHYgCMIOBEHYgSAIOxAEYQeC+H+OzjyUGOI3FwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(x_train[87], cmap='Greys')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHwj9GfuUjnZ"
      },
      "source": [
        "把輸入的資料做 normalization 是很好的習慣。原因有好幾個, 比方說:\n",
        "\n",
        "1. 每個 feature 範圍不同時, 常常會由數值大的主導。Normalization 可以避免這種事情發生。\n",
        "2. 因為像 ReLU 在大於零的部份就是 $f(x) = x$ 這樣的函數, $x$ 越大, 值就越大, 甚至非常大。\n",
        "3. 再來是穩定性的問題, 神經網路的學理研究就喜歡把所有 feature, 所有 weight 都假設在「平均值 0, 標準差 1」的常態分布。這樣的狀況也證實有各種良好特質。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHJ1jjjtUjnZ"
      },
      "source": [
        "## 5. 優化方式的調整\n",
        "\n",
        "### 5.1 改善學習方式的兩大考量\n",
        "\n",
        "我們用 SGD 可以說是最標準的方式, 事實上所有優化 (學習) 方式基本上都是 gradient descent。不過我們有兩大方向可以考量改善:\n",
        "\n",
        "#### (1) 加入 momentum\n",
        "\n",
        "想像我們的 loss function 畫出來像一座高低起伏的山, 我們在山中的某一個點, 想要走到山下。Gradient descent 會帶我們從「目前看到下坡最陡的方向」下山。但是走了兩步後我們可能發現 gradient descent 又說要走另一個方向。於是在那繞來繞去才終於下山。因此我們想要以更「穩定而勇敢」的方式, 比較朝向一個目標前進, 就加入所謂的 momentum。\n",
        "\n",
        "#### (2) learning rate 變速器\n",
        "\n",
        "我們說 learning rate 調夠小, 我們的神經網路基本上都該收斂的。不過調太小可能學非常慢, 大了一點又怕跳過頭。於是有一些「變速」的方式被研發出來, 一般的原則就是「開始快、接近目標時變慢」。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilAXD3TOUjna"
      },
      "source": [
        "### 5.2 在 Keras 選用不同學習法!\n",
        "\n",
        "\n",
        "我們就先 import 想要的學習法, 如果不知道可以考慮用 Adam, 前兩大項考量 Adam 都有考慮進去!\n",
        "\n",
        "    from keras.optimizers import Adam\n",
        "\n",
        "然後在 compile 時說要用 Adam 即可。\n",
        "\n",
        "    model.compile(loss='mse', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "Adam 其實有些參數可調, 但我們這暫不多談。"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [conda env:tf2py38]",
      "language": "python",
      "name": "conda-env-tf2py38-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}